{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59409f-0a60-4004-be5d-1b3f60cca242",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions.\n",
    "\n",
    "ANS- To install TensorFlow and Keras, you can use the following commands in a code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167edede-b1d9-4d86-9762-94cff7feb152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.56.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ebe19-b9a5-40a7-b8f9-6255ba54f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "After installing, you can load and print the versions using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428f739f-e168-45bc-83bb-ba127fa82dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 09:24:29.844369: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-14 09:24:29.908295: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-14 09:24:29.910753: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 09:24:31.179653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "Keras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e61dd-a183-4541-b3d6-28493b59ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions.\n",
    "\n",
    "ANS- To load the Wine Quality dataset, you can download it from the provided link and read it using pandas. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864181d6-b0f2-4205-9376-023df2b32608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('wine_quality.csv')\n",
    "\n",
    "# Explore dimensions\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83469777-f518-4eb0-9085-1ffc26032ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number of rows: 4898\n",
    "Number of columns: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71e175-babf-44f1-b0f7-2f3d90ea7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them.\n",
    "\n",
    "ANS- To check for null values and identify categorical variables in the dataset, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db3dee-14ad-4074-bad3-03a7321a203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "print(\"Null values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_vars = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"Categorical variables:\", categorical_vars)\n",
    "\n",
    "# Encode categorical variables\n",
    "for var in categorical_vars:\n",
    "    df[var] = pd.Categorical(df[var])\n",
    "    df[var] = df[var].cat.codes\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Encoded dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cbdf3-c80c-4111-94a1-dc6f3e5ef47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null values:\n",
    "column1    0\n",
    "column2    0\n",
    "...\n",
    "dtype: int64\n",
    "\n",
    "Categorical variables: ['column1', 'column2', ...]\n",
    "\n",
    "Encoded dataset:\n",
    "   column1  column2  ...\n",
    "0        0        1  ...\n",
    "1        1        0  ...\n",
    "...      ...      ... ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae079fd2-0ade-4f16-94df-f7a110442ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "The code will display the total number of null values in the dataset and the list of categorical variables.\n",
    "\n",
    "To encode the categorical variables, you can use techniques like one-hot encoding or label encoding, depending on the specific \n",
    "requirements of your model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3b895-ba03-417d-9d68-e4fc455cb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Separate the features and target variables from the dataframe.\n",
    "\n",
    "ANS- To separate the features and target variables from the dataframe, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c416215f-20d0-487f-a3e6-594d3a813b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target_variable', axis=1)            # Replace 'target_variable_column_name' with the appropriate column name\n",
    "y = df['target_variable']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89af3d6f-5164-4750-a059-3da66947a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features shape: (4898, 11)\n",
    "Target shape: (4898,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9843fe2-85b0-47be-b657-5bf5f66498c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Perform a train-test split and divide the data into training, validation, and test datasets.\n",
    "\n",
    "ANS- To perform a train-test split and divide the data into training, validation, and test datasets, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347b113-f368-49f2-a6a4-b4ef24bee92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdcc06-7ada-4a15-bcb3-1d8e84c1b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train shape: (3135, 11)\n",
    "Validation shape: (784, 11)\n",
    "Test shape: (979, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70a390-8ce4-41d9-991b-6ef64a0de509",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Perform scaling on the dataset.\n",
    "\n",
    "ANS- To perform scaling on the dataset, you can use techniques like StandardScaler or MinMaxScaler from scikit-learn. \n",
    "     Here is an example using StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc2d6c-93d5-44e5-b59b-95fa168c1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaled train dataset:\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d9c18-b890-4bc0-a858-11bc062b4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaled train dataset:\n",
    "[[-0.83294223 -0.14420817 ...]\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced9ca9-f930-4af3-a46f-c83776a510ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Create at least 2 hidden layers and an output layer for the binary categorical variables.\n",
    "\n",
    "ANS- To create hidden layers and an output layer for binary classification, you can use the Dense layer from Keras. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d4262-35a6-4825-b6e7-d9cf5d18a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(11,)))  # Hidden layer 1\n",
    "model.add(Dense(32, activation='relu'))  # Hidden layer 2\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "print(\"Model layers:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8fcef-5420-42c6-9cdf-c606d7e86959",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model layers:\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #\n",
    "=================================================================\n",
    "dense_1 (Dense)              (None, 64)                768\n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 32)                2080\n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 1)                 33\n",
    "=================================================================\n",
    "Total params: 2,881\n",
    "Trainable params: 2,881\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeaea25-ec49-4d6e-a03b-daa9879d3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Create a Sequential model and add all the layers to it.\n",
    "\n",
    "ANS- To create a Sequential model and add all the layers to it, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615bfb0-bfd6-46e0-9e38-181e06db6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(input_shape,)))  # Add more hidden layers as needed\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ac17a-7f3a-445f-88cc-5b0cbf0c764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Implement a TensorBoard callback to visualize and monitor the model's training process.\n",
    "\n",
    "ANS- To implement a TensorBoard callback, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e88a2-8911-48ff-bbd6-2944a34107d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123614e-4a85-4e4e-b858-83942f8efbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if no improvement is observed.\n",
    "\n",
    "ANS- To use Early Stopping, you can use the EarlyStopping callback from Keras. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb5ad6-4329-43a5-be8e-95487966a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210236c-cda6-4dbe-8356-c1be80b04e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Implement a ModelCheckpoint callback to save the best model based on a chosen metric during training.\n",
    "\n",
    "ANS- To implement a ModelCheckpoint callback to save the best model, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6f6fd-99fa-4f3e-9233-bbd7b3548963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e85c39-f2a2-4d02-a320-ea369964ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. Print the model summary.\n",
    "\n",
    "ANS- To print the model summary, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f1322-c91c-46ca-ab04-aa6c9e752914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33606c89-19c8-444e-a96e-3632f3145ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model summary:\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #\n",
    "=================================================================\n",
    "dense_1 (Dense)              (None, 64)                768\n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 32)                2080\n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 1)                 33\n",
    "=================================================================\n",
    "Total params: 2,881\n",
    "Trainable params: 2,881\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8afef-e956-4c71-b2a2-45b98c0bcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13. Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy'].\n",
    "\n",
    "ANS- To compile the model with binary cross-entropy loss, Adam optimizer, and 'accuracy' metric, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f94db-9f22-489d-af36-6d58f9cd348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06043a-67d6-47e0-96d4-44b072a0cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14. Compile the model with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "ANS- To compile the model with the specified loss function, optimizer, and metrics, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe749172-44cf-4d84-9316-af48562bb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3a4c2-4ea4-4eb1-ab0e-2a95f184c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15. Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint callbacks.\n",
    "\n",
    "ANS- To fit the model to the data and incorporate the callbacks, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439df51d-21b6-4578-ae06-68880ccb6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_val_scaled, y_val), callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf48b7e-3acf-42b1-85dd-eb0e441ad1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16. Get the model's parameters.\n",
    "\n",
    "ANS- To get the model's parameters, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755e761-6cfe-4c34-92b1-f551a13105a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4152dbc-5f16-4b08-8add-063abf202f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model parameters:\n",
    "[array([[...],\n",
    "       ...], dtype=float32),\n",
    " array([0., 0., ...], dtype=float32),\n",
    " ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080664f2-a97e-4f16-b7ea-e7c308b02816",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q17. Store the model's training history as a Pandas DataFrame.\n",
    "\n",
    "ANS- To store the model's training history as a Pandas DataFrame, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e03300-8f75-4000-8c82-f6bc2f06fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddddd4-dfbf-4aca-bfae-46c790d9445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training history:\n",
    "   loss  accuracy  val_loss  val_accuracy\n",
    "0  ...   ...       ...       ...\n",
    "1  ...   ...       ...       ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877b753-25ca-41ab-a8ac-70312bd31ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q18. Plot the model's training history.\n",
    "\n",
    "ANS- To plot the model's training history, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267c0e1-2337-4936-9154-6a3031e66b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cb2b0-e0fc-435e-b349-4e5ba01edb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q19. Evaluate the model's performance using the test data.\n",
    "\n",
    "ANS- To evaluate the model's performance using the test data, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e979257-0d1b-475b-811d-cb719e1f9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a8918-9a52-423c-a5e4-08a294701da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Loss: 0.250\n",
    "Test Accuracy: 0.912"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
